Прежде чем перейти к работе с самими файлами, нужно знать такое понятие как сериализация.
Сериализация - процесс преобразования объекта в поток байтов для сохранения или передачи в память, базу данных
или файл.
Это операция предназначена для того, чтобы сохранить состояние объекта для последующего воссоздания при необходимости.
Обратный процесс называется десериализацией.

Первый формат с которым мы познакомися - это CSV(Рисунок 1).
Формат CSV можно читать даже не зная как он устроен, но Python может помочь нам упростить работу с ним. 
Для чего используют формат CSV можно увидеть на Рисунке 2.

Как работать с CSV в Python увидим на Рисунке 3.
Теперь на практике:

Для того чтобы начать работать с CSV нужно сначала её импортировать.

import csv

Затем откроем csv файл и поработаем с ним, откроем как в прошлом уроке

import csv

with open('files/newsafr.csv', 'rt', encoding='UTF-8') as file: # открыли файл
    reader = csv.reader(file) # считали в переменную содержимое файла
    for row_number, row in enumerate(reader): # пройдёмся в цикле по содержимому, считывает он у нас по строчно поэтому
						# перебираем в цикле
        print(row_number, row) # выводим номер строки и само содержимое

# Вывод
0 ['guid', '_id', 'pubDate', 'description', 'link', 'title']
1 ['https://www.votpusk.ru/news.asp?msg=544347', '544347', 'Mon\\; 17 Oct 2016 00:28 +0300', 'Израильский турист погиб а еще трое получили ранения в результате автомобильной аварии в Йоханнесбурге Южная Африка Об этом сообщил 2 канал в воскресенье 16 октября Трагедия произошла когда автомобиль туристов стал участником ДТП а именно когда произошло лобовое столкновение Авария произошла всего через несколько дней после того как семья туристов в Грузии потеряла двух детей в автомобильной аварии MIGnews com', 'https://www.votpusk.ru/news.asp?msg=544347 ', 'Израильский турист погиб в ДТП в Африке']

Будет выведено, куча строк идентичного формата как строка с номером 1, в строке с номером 0 - указаны заголовки CSV формата.
Нужно также уметь немного анализировать информацию в CSV файле - так как нужно понимать, где заголовки например и тд.
Сейчас в нашем файле заголовком является последний элемент в списке, то есть обратиться к нему можно как row[-1]
Давайте попробуем

import csv

with open('files/newsafr.csv', 'rt', encoding='UTF-8') as file:
    reader = csv.reader(file)
    for row_number, row in enumerate(reader):
        print(row_number, row[-1])

# Вывод
0 title
1 Израильский турист погиб в ДТП в Африке

Видим, что вывелся только заголовок.

Теперь попробуем переформатировать csv файл сразу в список - это можно сделать просто применив list()

import csv

with open('files/newsafr.csv', 'rt', encoding='UTF-8') as file: # открыли файл
    reader = csv.reader(file) # считали файл
    news_list = list(reader) # преобразовали данные

for news in news_list: # перебрали данные
    print(news[-1]) # вывели только последний элемент из массива, то есть заголовки

# Вывод
title
Израильский турист погиб в ДТП в Африке

Как мы заметили, у нас постоянно выводится title, и это немного неудобно, так как в коде его постоянно надо будет учитывать, а
делать постоянные проверки, не круто, поэтому давайте избавимся от него другим способом.
Так как все записи у нас хранятся в списке, то и удалить запись можно как из списка

header = news_list.pop(0) # удаляем первую запись и на всякий случай сохраняем её в переменную header если пригодится
for news in news_list:
    print(news[-1]) 

# Вывод
Израильский турист погиб в ДТП в Африке
Ростуризм просит турбизнес сообщать людям о риске заражения в Африке

Как видим слова title больше нет

И из плюсов такого метода работы - это можно посчитать и количество данных(в данном случае новостей) в нашем файле с помощью
функции len().
print(f'В этом файле {len(news_list)} строк')

Теперь поработаем с DictReader

import csv

with open('files/newsafr.csv', 'rt', encoding='UTF-8') as file:
    reader = csv.DictReader(file) # считываем в словарь
    for row in reader:
        print(row)

# Вывод
{'guid': 'https://www.votpusk.ru/news.asp?msg=544347', '_id': '544347', 'pubDate': 'Mon\\; 17 Oct 2016 00:28 +0300', 'description': 'Израильский турист погиб а еще трое получили ранения в результате автомобильной аварии в Йоханнесбурге Южная Африка Об этом сообщил 2 канал в воскресенье 16 октября Трагедия произошла когда автомобиль туристов стал участником ДТП а именно когда произошло лобовое столкновение Авария произошла всего через несколько дней после того как семья туристов в Грузии потеряла двух детей в автомобильной аварии MIGnews com', 'link': 'https://www.votpusk.ru/news.asp?msg=544347 ', 'title': 'Израильский турист погиб в ДТП в Африке'}
# и таких строк для каждой новости

Как мы видим у нас появилась пара ключ-значение для каждого элемента файла csv
И теперь мы можем обращаться к нашим заголовкам не как к индексам, а как к ключам

import csv

with open('files/newsafr.csv', 'rt', encoding='UTF-8') as file:
    reader = csv.DictReader(file)
    for row in reader:
        print(row['title']) # обратились к title

# Вывод
Израильский турист погиб в ДТП в Африке
# и тд

Теперь разберёмся со следующей проблемой. CSV файл - это по сути файл данные в котором разделены запятыми.
То есть выглядит они примерно так:

https://www.votpusk.ru/news.asp?msg=534896,534896,"Wed, 16 Sep 2015 14:36 +0300"

Но встречается следующая проблема, если открывать русским Excel, то только запятые могут означать например - дробные числа, например,
2,5 или 3,14 
И можно неправильно всё это считать.
Для этого нужно настроить файл, чтоб например - ставились не запятые, а точки с запятой ;
Решить это можно следующим образом

import csv

# считали данные в список
with open('files/newsafr.csv', 'rt', encoding='UTF-8') as file:
    reader = csv.reader(file)
    news_list = list(reader)

header = news_list.pop(0) # сохранили заголовки
with open('files/newsafr2.csv', 'w', encoding='UTF-8') as file: # создали второй файл - в который - мы всё сохраним
    writer = csv.writer(file, delimiter=";") # указали, что в качестве разделителя - будем использовать ;
    writer.writerow(header) # записали заголовок
    writer.writerows(news_list) # записали заголовки

Если мы выполним данный код то заметим, что в файле появятся дополнительные пробелы, чтоб их избежать, нужно добавить
параметр new_line при открытии файла

header = news_list.pop(0)
with open('files/newsafr2.csv', 'w', newline='') as file: # сюда вставляем new_line, а также убираем encoding - так как мы запишем
							# в кодировке питона, а нам нужно чтоб была обычная под windows
    writer = csv.writer(file, delimiter=";")
    writer.writerow(header)
    writer.writerows(news_list)

Теперь разберёмся с расстановкой ковычек в файле
Для этого - нам поможет такое параметр как quoting
У этого параметра могут быть несколько значений

csv.QUOTE_NONE - Полные запрет ковычек, не ставим их вообще
csv.QUOTE_ALL - Обернёт все данные в ковычки, не смотря на значения
csv.QUOTE_MINIMAL - ставим ковычки там, где без них обойтись нельзя

Прописываем их во writer 
writer = csv.writer(file, delimiter=";", quoting=csv.QUOTE_ALL)

Но настоек на самом деле куча, и прописывать их постоянно будет неудобно поэтому у нас есть специальная настройка, куда это можно
всё прописать
И настройки можно сохранять следующим образом

csv.register_dialect("csv_comma_quote_all",delimiter=";", quoting=csv.QUOTE_ALL) # прописали настройки и самое главное
# дали первым параметром - имя этим настройкам

with open('files/newsafr2.csv', 'w', newline='') as file:
    writer = csv.writer(file, dialect="csv_comma_quote_all") # и тут уже прописываем файл и имя используемых настроек
    writer.writerow(header)
    writer.writerows(news_list)

Теперь попробуем записать в файл с помощью DictReader

import csv

with open('files/newsafr.csv', 'rt', encoding='UTF-8') as file: # открываем файл из которого считываем
    reader = csv.DictReader(file)
    with open("files/newsafr3.csv", "w", newline="", encoding="UTF-8") as file3: # открываем файл в который будем записывать
        writer = csv.DictWriter(file3, fieldnames=reader.fieldnames) # используем DictWriter, чтоб записывать и важно передать
								# параметр fieldnames, которые покажет где хранятся заголовки

        writer.writeheader() # записываем заголовки
        for row in reader: # перебираем в цикле строки 
            row['title'] = row['title'].upper() # делаемз заголовок большим(это абсолютно необязательно и не имеет отношения к задачи)
            writer.writerow(row) # построчно записываем


Теперь поработаем с JSON форматом
JSON формат очень напоминает питоновскую комбинацию из словарей из списков, который в друг друга вложены. Рисунок 4.
Для чего нужны JSON форматы - можно увидеть на Рисунке 5.
Как работать с JSON можно увидеть на Рисунке 6.
Поработаем на практике:

import json

with open('files/newsafr.json', encoding='UTF-8', newline="") as f: # открыли наш json файл
    json_data = json.load(f) # сохранили все его данные в переменную

print(type(json_data), json_data) # и посмотрим его тип и что в нём хранится

# Вывод

<class 'dict'> {'rss': {'_xmlns:votpusk': 'https://www.votpusk.ru/news.asp', '_version': '2.0', # и тд

Видем, что у нас сохранилось всё в словарь, а также словарь и находится в данной переменной

Теперь попробуем выполнить следующую задачу: вывести и посчитать все ключи 'title' в данном json файле
Для этого нужно изучить путь к ключу 'title' и последовательно доставать его

import json

with open('files/newsafr.json', encoding='UTF-8', newline="") as f:
    json_data = json.load(f)

print(type(json_data)) # type dict
print(new_list := json_data['rss']['channel']['items']) # на данном уровне у нас находится 'title' и мы записали все
							# 'title' в список и он вывелся благодаря моржовому оператору
print(len(new_list)) # 40

И теперь в массиве мы можем перебрать эти title

for news in news_list:
    print(news['title'])

# Вывод 

Израильский турист погиб в ДТП в Африке
Ростуризм просит турбизнес сообщать людям о риске заражения в Африке
Открытие сафари кемпа Belmond Eagle Island Lodge в Ботсване после реновации
...
# и тд

Чтоб сохранить данные как json файл воспользуемся следующий кодом

import json

with open('files/newsafr.json', encoding='UTF-8', newline="") as f: # откроем json файл с данными
    json_data = json.load(f) # считаем данные

with open('files/newsafr2.json', 'w', encoding='utf-8', newline="") as f: # откроем файл newsafr2 на запись
    json.dump(json_data, f) # запишем туда json файл

Итого в файле будет следующие данные:

{"rss": {"_xmlns:votpusk": "https://www.votpusk.ru/news.asp", "_version": "2.0", "channel": 
{"description": "\u0410\u0444
...
# и тд

Тут мы видим странные символы \u0410\u0444 хотя в изначальном файле их не было, это такое восприятие у русского языка.
Мы всё равно сможем считывать эти данные в Python и работать с ними, и Python будет выводить их нормальными буквами, но
оставлять так это не дело, для этого нам поможет следующая настройка

with open('files/newsafr2.json', 'w', encoding='utf-8', newline="") as f:
    json.dump(json_data, f, ensure_ascii=False) # ставим настройку ensure_ascii=False

Теперь у нас в выходном файле будет нормальный русский язык. Одну проблему исправили, но с точкий зрения читаемости, там
всё как одна большая строка, было бы классно если было бы что-то по аналогии с pprint в Python
и такая штука есть, нам нужен параметр indent

with open('files/newsafr2.json', 'w', encoding='utf-8', newline="") as f:
    json.dump(json_data, f, ensure_ascii=False, indent=2) # ставим indent=2 и 2 будет означать, что будет два проблема
							# у каждого ключа

И теперь выходной файл будет выглядеть так:

{
  "rss": {
    "_xmlns:votpusk": "https://www.votpusk.ru/news.asp",
    "_version": "2.0",
    "channel": {

Выглядит намного лучше, но на самом деле эти отступы нужны только нам для читаемости, самому Python - они не нужны и 
можно без них работать.

Теперь посмотрим как нам работать с JSON как со строкой

import json

with open('files/newsafr.json', encoding='UTF-8', newline="") as f: # вновь открываем файл для чтения
    json_data = json.load(f) # считываем данеые как словарь

json_str = json.dumps(json_data) # затем переводим наши данные из словаря в строку
# тут важное примечание - если попробовать сразу из файла в строку, то будет ошибка, поэтому
# мы делаем дополнительное действие как считывание данные в словарь

print(json_str) # выведет снова json файл, но с непонятной кириллицей \u0444\u0435
print(type(json_str)) # <class 'str'>

Чтоб исправить кириллицу нужно вновь прописать параметр

json_str = json.dumps(json_data, ensure_ascii=False)

print(json_str)
теперь всё будет окей

Теперь попробуем сохранить нашу строку в json файл

#открываем и считываем наши данные
with open('files/newsafr.json', encoding='UTF-8', newline="") as f: 
    json_data = json.load(f)

json_str = json.dumps(json_data, ensure_ascii=False)

# записываем наши данные в переменную с помощью json.loads и передаём нашу строку
json_data2 = json.loads(json_str) 
print(type(json_data2)) # увидем тип 'dict'

И готово, теперь мы можем вновь его обрабатывать и зписывать

Перейдём к следующему формату - YAML
YAML - выглядит примерно так:

rss:
  _version: '2.0'
  _xmlns:votpusk: https://www.votpusk.ru/news.asp
  channel:
    category: Туризм - Африка

Как он выглядит можно увидеть на Рисунке 7
Для чего его используют можно увидеть на Рисунке 8
Как использовать YAML в Python - Рисунок 9
!!! Чтоб использовать библиотеку YAML в Python - её нужно дополнительное устанавливать
Примеры к YAML разбирать не будем

Теперь перейдём к XML файлам.
Он выглядит примерно так

<?xml version='1.0' encoding='windows-1251'?>
<rss version="2.0">
	<channel>
		<title>Новости Африка</title>
		<link>https://www.votpusk.ru/news.asp</link>

Подробнее можно на Рисунке 10.
Для чего он нужен на Рисунке 11.
О тонкостях его устройства можно посмотреть на Рисунк 12.
В отличии от работы с другими типами файлов - здесь используется язык поисковых запросов XPath
XPath - простой язык поиска по XML

Поиск одного элемента: root.find(query)
Поиск нескольких элементов: root.findall(query)
query = XPath

Перейдём к работе на практике.

Для того, чтобы начать работать на практике нам нужно сделать импорт данной библиотеки

import xml.etree.ElementTree as ET

Разберёмся на следующем коде и задача та же самая - вывести все заголовки и количество новостей

import xml.etree.ElementTree as ET # импортируем библиотеку

parser = ET.XMLParser(encoding='windows-1251') # ставим кодировку которую мы получаем
tree = ET.parse("files/newsafr.xml", parser=parser) # парсим наш файлы и в отличии от дургих файлов - нам не надо пользоваться open
print(tree) # посмотрим как это выглядит -> <xml.etree.ElementTree.ElementTree object at 0x0000017ADA307F70>

root = tree.getroot() # получаем корень
print(root.tag) # rss
print(root.text) # ''
print(root.attrib) # {'version': '2.0'}

# теперь чтоб найти все новости и записать их в список - нам нужно посмотреть на внутреннее устройство нашего xml файла
# и мы видим, что каждая новость находится в пути channel/item его мы и указываем
news_list = root.findall('channel/item') # считываем все новости по пути channel/item
print(len(news_list)) # выведем количество новостей -> 40

for news in news_list: # в цикле попробуем вывести названия всех новостей
    title = news.find('title') # записываем в переменную каждый тэг title
    print(title.text) # выводим текст у title

# Вывод
Израильский турист погиб в ДТП в Африке
Ростуризм просит турбизнес сообщать людям о риске заражения в Африке
...
# и тд

Можно было сделать и покороче

title_list = root.findall("channel/item/title")
for title in title_list:
    print(title.text)

# Вывод будет тем же самым

А теперь попробуем создать новый файл xml

tree.write("files/newsafr2.xml")

И когда мы откроем файл, мы вновь увидем непонятные символы
Для этого нужно поставить нужную кодировку

tree.write("files/newsafr2.xml", encoding='windows-1251')

Готово!